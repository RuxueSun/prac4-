#################### 1 netup function
## purpose:
## Input:
##      d:a vector giving the number of nodes in each layer of a network.
## Output:
##      h: a list of nodes for each layer.
##      w: a list of weight matrices.
##      b: a list of offset vectors.

netup <- function(d){
  
  # calculate the number of layers
  layer <- length(d)
  
  # Initialize weight matrices with U(0, 0.2) random deviates
  W <- vector('list', layer-1)
  for (i in 1:(layer-1)){
    W[[i]] <- matrix(runif(d[i] * d[i+1],0 , 0.2), nrow = d[i+1], ncol = d[i])
  }
  
  # Initialize offset vectors with U(0, 0.2) random deviates
  b <- vector('list', layer-1)
  for (i in 1:(layer-1)){
    b[[i]] <- runif(d[i+1],0,0.2)
  }
  
  # Initialize nodes for each layer
  h <- vector('list', layer)
  
  # nodes for first layer is the values of input data
  h[[1]] <- numeric(d[1])
  
  # nodes for other layers
  for (i in 2:layer){
    for (j in 1:d[i]){
      h[[i]][j] <- max(0,W[[i-1]][j,] %*% h[[i-1]] + b[[i-1]][j])
    }
  }
  
  network <- list(h=h, W=W, b=b)
  
  return(network)
  
}

  
#################### 2 forward function
## purpose:
## Input:
##       nn: a network list as returned by netup.
##       inp: a vector of input values for the first layer.
## Output:
##       updated network list.

forward <- function(nn,inp){
  
  # recall the results of netup function
  h <- nn$h
  W <- nn$W 
  b <- nn$b 
  
  # values for the first layer
  h[[1]] <- inp
  
  # nodes for other layers
  for (i in 2:length(W)+1){
    h[[i]] <- pmax(0, W[[i-1]] %*% h[[i-1]] + b[[i-1]])
  }
  
  network <- list(h=h, W=W, b=b)
  
  return(network)
}

#测试
set.seed(123)
nn_1 <- netup(c(4,8,7,3))
nn_2 <- forward(nn_1,c(5.1,3.5,1.4,0.2))

#################### 3 backward function
## purpose:
## Input:
##       nn: a network list as returned by forward.
##       k: output class.
## Output:
##       updated network list after adding dh, dW, db.

backward <- function(nn,k){
  
  # recall the results of forward function
  h <- nn$h
  W <- nn$W 
  b <- nn$b
  
  # calculate the layers
  layer <- length(h)
  
  # 
  dh <- vector('list', layer)
  dW <- vector('list', layer-1)
  db <- vector('list', layer-1)
  
  # pk
  #求和
  sum = 0
  for (i in 1:length(h[[layer]])){
    sum <- sum + exp(h[[layer]][i])
  }
  
  pk <- exp(h[[layer]][k])/sum
  
  # loss function
  L_i <- -log(pk)
  
  # dh的最后一个
  for (j in 1:length(h[[layer]])){
    if (j != k){
      dh[[layer]][j] <- exp(h[[layer]][j])/sum
    }else{
      dh[[layer]][j] <- exp(h[[layer]][j])/sum - 1
    }
  }
  
  # 求dl
  dl <- vector('list', layer)
  
  # 给dl第一个列表赋值 只用到第二到layer个
  dl[[1]] <- numeric(length(h[[1]]))
  
  # 求dl的2到layer个列表和dh的其他
  for (i in (layer-1):1){
    for (j in 1:length(h[[i+1]])){
      if (h[[i+1]][j] > 0){
        dl[[i+1]][j] <- dh[[i+1]][j]
      }else{
        dl[[i+1]][j] <- 0
      }
    }
    dh[[i]] <- t(W[[i]]) %*% dl[[i+1]]
  }

  
  # 求对b的偏导
  for (i in 1:(layer-1)){
    db[[i]] <- dl[[i+1]]
  }
  
  # 求对W的偏导
  for (i in 1:(layer-1)){
    dW[[i]] <- dl[[i+1]] %*% t(h[[i]])
  }
  
  network <- list(h=h, W=W, b=b, dh=dh, dW=dW, db=db)
  
  return(network)
  
}

backward(nn_2,1)

#################### 4 train function
## purpose:
## Input:
##       nn: a network list as returned by backwork.
##       inp: given input data in the rows of matrix.
##       k: a vector shows corresponding labels (1, 2, 3 . . . ).
##       eta: the step size.
##       mb: the number of data to randomly sample to compute the gradient.
##       nstep: the number of optimization steps to take.

#第一问：构建搭建神经网络netup(d)
#第二问：插入了输入层数据forward(nn,inp)
#第三问：计算损失函数，得到新的W和B和H backward(nn,k)
#第四问：用eta为步长更新W和B
train <- function(nn, inp, k, eta = 0.01, mb = 10, nstep = 10000) {
  
  #从输入矩阵里随抽取mb个样本
  sp <- sample(1:nrow(inp),mb,replace = True)
  
  for(i in 1:mb){
    #第一次，输入数据到网络
    nn <- forward(nn,inp[sp]) #nn是一个包含WBH的列表
    
    #recursive to optimize the network
    for(j in 1:nstep){
      nn_D <- backward(nn,k)
      #update the parameter
      nn$W <- nn$W-eta*nn_D$dW
      nn$b <- nn$W-eta*nn_D$db
      
    }
  }
  
  return(nn)
}

#################### 5 
## purpose:

# 生成训练集和测试集
num_rows <- nrow(iris)
test_index <- seq(5,num_rows,5)
test_data <- iris[test_index,]
training_data <- iris[-test_index,]

# set up d, which is the number of nodes in each layer of a network.
d <- c(4,8,7,3)

# 训练iris数据
set.seed(123)
nn_1 <- netup(d)
nn_2 <- forward(nn_1, training_data[1,1:4])
nn_3 <- backward(nn_2,1)
nn_4 <- train(nn_3,training_data[,1:4],training_data[,5],eta = 0.01, mb = 10, nstep = 10000)






